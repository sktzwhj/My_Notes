关于spark的第一篇paper发表在HotCloud。

spark的目的并不是完全要替换掉mapreduce。而是说mapreduce并不适合于一些需要重用working set的应用。典型的这种应用
包括：很多机器学习算法，交互式的数据分析工具。

为什么性能不好呢，用例子来说明。

比如对于mapreduce，如果我们在做一些机器学习算法的时候，我们需要反复地将数据集应用于算法中（比如提督下降法），那么这就会导致
每一次都是一个mapreduce的任务，因而我们需要将数据反复地load进来（从磁盘），所以性能不好。

另一种应用是交互式的数据分析，比如说SQL查询，hadoop在进行查询的时候，需要用一个mapreduce任务去将数据读到memory中。

Spark的最大亮点叫做RDD(Resilient distributed dataset)，用户可以显式地将数据cache在内存当中。而且当一个RDD失效了，
有足够的信息可以指导恢复。可以理解RDD其实就是一种共享内存模型。

首先看Spark的编程模型：

在使用spark的时候，用户需要写driver program，这里面包括了high level的控制流以及一些并行操作。
那么spark的编程模型主要包括两个抽象：1. RDD， 2. 在数据集上的并行操作

RDD。RDD中包含了足够的信息来重建这个RDD，因而容错是可以做到的。
创建一个RDD的方法包括：1. 从HDFS文件系统中的文件来 2. 把一个scala的collection进行并行化，将其拆分到多个node上 3. 
转换一个已有的RDD; 4. 通过改变一个已有RDD的持久性，(cache要求一个dataset常驻内存从而可以重用，save会将一个RDD写到磁盘)

不过cache只是一个hint，因为如果机器确实没有这么大的内存的话，还是需要将这些空间释放掉。


再来看什么叫并行操作：
1. reduce，将一些数据集元素合并起来并且计算一些结果
2. collect，将数据集的所有元素发送给driver program。
3. foreach，将元素通过用户提供的函数来进行传递。

共享变量（对于类型有严格的限制）：
1. 广播变量 broadcast variables  被多个并行操作共享的变量
2. 累加器 

在写代码的时候，比如我们调用points.foreach，那么我们实际上是调用了spark里面的foreach并行操作。

Spark是建立在Mesos的基础上的，Mesos是一个集群操作系统，负责进行分布式计算的资源分配。

总结一下，感觉spark最大的特点就是RDD，那么说到底就是怎么样把中间结果优雅地放在内存里面。就工程实现角度来讲，肯定是有一定困难
的，但是就想法来说，有那么新颖么？或者是我还没有领悟到其精要所在？