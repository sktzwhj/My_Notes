前两天处理数据集的时候心想,自己用的处理办法实在是太笨太brute-force了,于是心想有没有什么简单快捷的方法.因而说把mapreduce
以及spark这两个系统了解一下吧!

这篇就先从mapreduce开始.

首先需要认识到mapreduce是一个编程模型.其目的就是把分布式计算当中那些基础设施的东西对用户隐藏,使得并没有分布式系统等知识
的用户可以方便地进行分布式计算.

map和reduce实际上是对于一个分布式计算任务的抽象.并且map和reduce都是需要用户去实现的.