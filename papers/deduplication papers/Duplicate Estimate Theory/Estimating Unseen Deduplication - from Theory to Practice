Author: Danny Harnik, etc. from IBM Research
Published in FAST'16
Date:09/06/2016

The main idea of this paper is that it is very important to estimate how much can a dataset benefit from dedup. 

The state-of-art: some vague estimation , full scan the data at hand.

This work uses a work in 2011 named Valiants which is a breakthrough paper. That paper indicates that at least O(n/logn) of 
data must be inspected. 

According to the paper, 15% of sample is sufficient for a good estimation on all workloads. And in practical, 3% or even 
less is enough. 

The result is: 
The method can achieve 3x time improvement over the state of art scans. The time improvement varies according to the data and the
medium on which data is stored. 








