Author: Zhuan Chen from U of Rochester
Published in: FAST'16
Date: 04/06/2016

The metadata mentioned here is like logical to physical block mapping, physical block reference counters, block fingerprints. 

The key idea of this paper is to use reorder rather than certain hardware or log to achieve the consistency of metadata.  Because the writes 
for flash is very expensive. 

Traditional methods to keep the consistency between data and their metadata:

journaling, easy to understand, like ext file systems.  
shadowing, use a copy-on-write fashion, and use atomic modifying of the file index to point the file to the new version. 
Soft update approach, carefully orders the writes in file system operations. 

Some metadata updates can be merged (if these metadata updates fall into the same metadata block) while some cannot. e.g., if there is
some dependency between the metadata updates, merging would cause  some deadlock. In order to solve this, the idea of this paper is to
delay some non-critical updates. (non-critical means the client I/O response would not be affected.)

The consistency model: strong, weak (async). For weak consistency model, the delaying of metadata updates is possible. However, for some
applications and applications, this might be hindered by the sync writes. 

The only problem that would happen in failure is that some ref numbers might be higher than real. 

anticipatory I/O delay and merge. if we temporarily stop issuing writes to the device, we can merge some writes to reduce the number of total 
writes. Thus, in high density write scenario, short anticipatory device idle period would produce high degree of merging. So some heuristic 
methods can be used to decide whether to do this. 


What does it mean of the metadata writes falling into the same block?

Since it is harmful to dedup the critical info like superblock, this paper avoids this by recognizing the addresses. 