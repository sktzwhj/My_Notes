Authors: Fabiano C. Botelho et al. 
Published in FAST'13
Date:23/07/2016

这篇文章的题目就让我觉得很有意思，大概的意思就像是我们在存储系统中如何把数据的痕迹删除干净。

本文提到的几种reference index方法：

 1. 最简单的就是，给每一个chunk维护一个counter，但是这样的问题在于由于存储系统当中的failure非常复杂，因此实现起来正确性
 非常难以保证。
 
 2. 一个稍微简单点的方法是枚举整个存储系统当中存活的文件，因为其实我们没有必要去计数，只要有一个reference的chunk都不能被
 删除掉。但是不管是counter还是这种方法，问题在于对于large scale的存储系统， 这些index都已经太大，无法放在内存当中。因此，
 把它们写到磁盘是不可避免的选择。但是写到磁盘上就要面临磁盘随机访问的糟糕性能。
 
 3. 因此，当数据太大的时候，一个自然的想法就是把数据分块。由于在dedupe系统当中，我们的数据实际上是分别存储在不同的container当中的， 
 因此可以按照逐个container的方式来进行处理。每次只要把这个container当中的fingerprint的index读到内存当中就可以了。
 每次我们对一个container进行扫描的时候，我们需要遍历整个文件系统来找到当前container当中是否存在dead chunk，但是这样
 的问题就是I/O，因为我们需要遍历太多次文件系统了。。（我的问题是，难道我们不能把文件系统的元数据也cache在内存里面么）？
 
 4. bloom filter， 用这个的原因主要是因为full index of references开销非常大， 而且bloom filter会有false positive. 
 
 5. Bit Vecotr, 为了避免false positive，可以使用bit vector技术，每个bit代表一个数据块，而数据块的索引由其所属container的
 id和内部偏移决定。因此bit vector等于是用位图法标记存储系统所有数据块的使用情况。构造bit vector需要遍历所有recipe（可能还要读取
 container的元数据区确定偏移）；然后遍历指纹索引时，找出没有标记的指纹。
 
 6. Perfect hashing (本文提出的解决方案)。 
 
 在垃圾回收时，可以将存储系统中的指纹集看成静态集合。当我们知道集合的所有n个元素时，我们可以构造一个哈希函数，将所有元素
 映射为0~n-1之间的整数，并不产生冲突。这个函数就是完美哈希函数。这个算法的关键是如何在遍历recipe时构造完美哈希函数。
 有了哈希函数后，只需遍历指纹索引，找出不在哈希表中的指纹进行回收即可。
 
这种方法的内存开销比bit vector稍高（在不影响性能的情况下，大约每个块占2.54bits），但是无需知晓偏移信息。
 
bit vector的内存开销比bloom filter低，无false positive。但是它需要获知每个数据块在container内部的偏移，要么增加recipe和指纹索引的存储开销，要么增加构造bit vector的时间（临时读取container的元数据区）
 