Authors: Min Fu et al. from HUST
Published in ATC'14
Date: 24/07/2016

这篇文章着手解决两个问题，一个是restore的问题，另一个是garbage collection的问题。

对于restore，问题在于rewrite中判断fragmented chunks非常困难。而对于GC, 主要是merge操作非常的耗时。 

GC受到fragmentation的影响主要表现在那些不被任何backup version引用的data chunk也是分散在各处的。

在这种情况下，由于在GC中，我们需要将那些没有引用的chunk找出来，然后把这里面有用的数据拷贝出来到别的container，然后再把
原来的那些container回收了。但是由于fragmentation，每个container里面包含的无引用chunk的数量非常少。因而，使得GC的
效率很低。

因为存在fragmentation，所以为了提高效率，在restore的时候，container是restore buffer的pre-fetch单位。但是这样的话
读的效率实际很低，因为存在read amplification。

已有的解决方案: rewrite，就是重写那些重复但是fragmented的chunks。

这里需要区分的两个概念： 

sparse container & out-of-order container。
以往的rewrite算法解决的主要是out-of-order container的问题，但是没有解决sparse container的问题。

因而本文的一个重要关注点是相邻的两个backup version之间的相似度是很高的，因此从上一个版本backup中收集到的historical 
information可以被用来提高下一个版本。 具体做法如下： 在每一次backup过程中，我们rewrite上一次backup中说明的可能存在
sparse container的情况，然后记录下本版本backup中正在逐渐变得fragmenation的container以在下一次重写。

在垃圾收集中，由于HAR已经将sparse container消除了，因而我们就不需要再去判别sparse chunks了，只需要找到valid containers
而不是valid chunks. 