Note that the lower bound for comparison-based sorting algorithm is Omega(n). 

Union-Find Set 

why the time complexity for list-based union-find set is O(logn) to add an element?

because the list is sorted. 

Radix-sort is a specialization of lexicographic sorting where bucket-sort is used as the stable sorting in every dimension.


Maps and Dictionaries

A map models a serachable collection of key-value entires. 

Text Processing

(1) brute-force pattern matching

(2) boyer-moore heuristics. 

looking-glass heuristic

comparing P with a subsequence of T moving backwards

character-jump heuristic

when a mismatch occurs at T[i] = c
if P contains c, shift P to align the last occurrence of c in P with T[i]
else, shift P to align P[0] with T[i+1]

To this end, we need to build a last-occurrence function when using boyer-moore algorithm. The occurrence function just indicate where
does a character lastly appeared. 

Note that there are two cases, (1) the last occurrence of P[i] has already be compared, (2) the last occurrence has not been comapred 
yet. 

1+l is the length to the last occurrence, j is the current position. if l+1<j, that means we have not compared the last occurrence yet. 
If 1+l>j, that mean we have already compared the last occurrence. 

Every new comparison is started from the end of the pattern, so the new j is always m-1 where m is the length of the pattern. However, 
for i, since the pattern is moved forward. 我们只是把last occurrence和之前比较失败的地方对齐了，但是真正的比较还是要从结尾开始。所以，i = i + (m - (l+1))或者
i = i + (m-j)，　也就是说，因为L序列只记录最后一次出现，如果最后一次出现已经被比较过了，那么只往后走一格．

Boyer Moore 的时间复杂度是O(nm + s),但是这是最坏情况下，虽然和brute-force差不多，但是实际运行会好很多．

(3) KMP Algorithm

In order to use KMP algorithm, we have to calculate a Failure function.

KMP preprocess the pattern to find matches of prefixes of the pattern with the pattern itself. 

失败函数的值可以理解为若当前的比较失败，和当前后缀相同的最长前缀的长度。所以在brute-force的基础上，如果P[j]!=T[i]，那么j = F(j-1)

这里注意到在boyer-moore算法中，找到匹配的条件是j = 0， 在KMP中， 找到匹配的条件是j = m - 1。因为前者是从后往前比较，而后者是从前往后比较。

这里还要注意到一个特别的情况就是，如果j已经是0了， 那么说明已经没有可能通过前缀再找到什么合适的匹配了，那么这个时候j本来就在pattern的头部，只要把i = i+1就可以
了。

还有failure function的计算，其本身就是KMP算法。

首先j = 0, i = 0; 每匹配上一个， F[i] = j +1 ,i++;j++,如果出现没有匹配成功的，那么这个时候j = F[j-1] 如果到最后还是没有找到， 那么F[i] = 0, i = i+1 

The time complexity for KMP algorithm is O(m+n).

KMP算法只要抓住主串不回溯的精要就可以了。

Graph

三种Graph的描述方式：
(1) Edge List Structure 
每个边指向它的两个节点．节点并不指向边
(2) Adjacency List Structure 
每个节点指向所有和它相邻的边
(3) Adjacency Map Structure 
用一个hash map，每一个节点指向所有和它相邻的边，不过这里的边都用另一个节点作为key
(4) Adjacency Matrix Structure 
用一个m*m的矩阵，如果两个节点之间存在一条边，那么对应矩阵的位置值为１

深度优先搜索

subgraph 

spanning subgraph　是子图，但是包含所有的节点

连通性：如果任意两个节点之间都有边，那么就说是连通的．

连通分量：maximal connected subgraph of G

Tree and forests
Tree:是一个图，但是没有cycle
forests:forests的连通分量都是tree

生成森林(spanning forest)：是一个图，是一个生成子图，这个子图是一个森林

深度优先搜索的复杂度为O(m+n)，这里m是边的数量，n是节点数量．

深度优先搜索算法

Note that since there is cycle in a graph, so it is important to do the checks in DFS. 

Algorithm DFS(G)
Input: graph G
Output: Labeling of the edges of G as discovery edges and back edges. 
{
for all u belongs to G.vertices()
	setLabel(u, UNEXPLORED);
for all e belongs to G.edges()
	setLabel(e, UNEXPLORED);
for all v belongs to G.vertices()
	if (v is UNEXPLORED)
		DFS(G,v)
}

DFS(G,v)
Input: a graph G and a vertex v
Output: Labeling of the edges of G in the connected component of v as discovery edges and back edges. 
{
	setLabel(v, VISITED);
	for all e belongs to v's incident edges
		if(UNEXPLORED == getLabel(e))
			setLabel(e, VISITED)
			u = getOpposite(e,v)
			if(u is UNEXPLORED)
				setLabel(u, VISITED)
				DFS(G,u)
		else
			setLabel(e,BACK )
}

深度优先搜索的性质：
(1) DFS遍历了图中所有连通分量的节点和边
(2) 被标注维discovery的边组成了一棵生成树

Path Finding Algorithm by extending DFS

Algorithm PathFinding(G,v,z)
Input: G, v, z
Output: a path 

setLaebl(v, VISITED);
S.push(v);
if(v == z)
	return S.elements();
for all e belongs to v's incident edges
	if(getLabel(e) == UNEXPLORED)
	{
		setLabel(e, VISITED);
		S.push(e);
		u = getOpposite(v,e);
		if(u == z)
			return S.elements();
		else if(u is UNEXPLROED)
			PathFinding(G,u,z);
		S.pop();
	}
	else
	{
		setLabel(e,BACK);
	}
	
	S.pop();
}


Algorithm CycleFinding(G,v,w)
Input 
Output
{
	S.push(v);
	setLabel(v,VISITED);
	for all e belongs to v's incident edges
		if(e is UNEXPLORED)
			S.push(e);
			w = getOpposite(e,v)
			if(w is UNEXPLORED)
			{
				setLabel(w,VISITED);
				pathDFS(G,w,z)
				S.pop();
			}
			else
			{
				T is a new Stack 
				repeat
				{
					o = S.pop();
					T.push(o);
				}until(o == 2);
				
				return T.elements();
			
			}
		S.pop();
}

宽度优先搜索

宽度优先搜索的特性
(1) 宽度优先搜素的路径组成了一棵生成树

有向图的强连通性：每个节点都可以到达其它所有节点

强连通判断的算法

求传递闭包

Floyd Warshall算法，其原理是

首先给所有的节点编上号，从１到n.G1 = G0(G)．然后每次两重循环，如果在Gi-1中存在一个k，vi和vk相邻,vk和vj相邻，那么就在Ｇi中将vi和vj直接连起来．

算法的时间复杂度是O(n3)

有向无环图以及拓扑顺序

Algorithm for Topological Sorting 

Number vertices, so that (u,v) in E implies that u < v

Use DFS for Topological Sorting

就是在DFS之前n = number of vertices, 然后在深度优先的最后给当前的v赋值为n，然后将n = n-1

Graph(2)

Shortest Path

Dijkstra Algorithm

无向图　　　边的权重是非负

Dijkstra(G,v)

for all u in G.vertices()
	if(u == v)
		D[u] = 0;
	else
		D[u] = inf.
		
Q is a priority queue which is used to store the vertices and the key is the D[].

while(Q is not empty)
{
	q = Q.removeMin();
	
	for each z in Q such that q is adjacent to u dp 
		if (D[u] < D[z] + w((z,q)))
			D[u] = D[z] + w(z,q);
				change the key of u in the Q;
}

return all the D

create an priority queue takes O(n) time. 
removeMin takes O(logn) time. 
the relaxation takes O(degree(u)logn) time. 

So the overall time complexity of Dijkstra algorithm is sigma(degree(u)+1logn) = n*logn + O(2m*logn) = O((m+n)logn).

Also O(mlogn)　因为连通图的边的数量肯定比节点多

为什么Dijkstra算法可以工作呢?

因为Dijkstra是一个贪心算法，那么如果我们能够证明已经被赋值的最短路径并不会被改变，就可以证明Dijkstra算法的正确性．证明可以是这样，我们每次更新一个节点的距离，
由于所有边权值都为正，按么就不会存在一个距离更短的没有被扩展过的点，所以就可以证明正确性．


最小生成树

首先是几个概念

生成子图
Subgraph of a graph G
containing all the vertices of G

Spanning tree. a spanning subgraph that is a tree. 

Minimum spanning tree (MST)
spanning tree of a weighted graph with minimum total edge weight

最小生成树　cycle property

Kruskal算法

首先，给每一个节点都定义一个cloud, 然后用一个队列，把所有的边都放进去，每次取出一条边，如果边的两端不在一个cloud里面，就合并，直到找到n-1条边

这里的cloud可以用find-union strcuture

Kruskal算法的复杂度？

每次处理一个节点时，我们要合并partition，复杂度为logn．因此一共就是n*logn，然后每次removeMin ，所以是m*logn

最小生成树Prim-Jarnik's Algorithm算法

Algorithm Prim-JarnikMST(G):
{
	pick any vertex v of G;
	D[v] = 0;
	for each u in G (u!=v)
		{
			D[u] = inf;
		}
	T = null;
	Q is a priority queue;
	((u,null), D[u]) is the element and D[u] is the key
	while Q is not empty do
	{
		(u,e) = Q.removeMin();
		add vertex u and edge e into T;
		for each vertex z in Q such that z is adjacent to u, do 
			if(w((u,z)) < D[z])
				{
					Ｄ[z] = w((u,z));
					change the (z,(u,z)) the element of vertex z in Q
					change D[z] the key of vertex z in Q;
				｝
	
	}
	
	return T;

}

时间复杂度: m*logn

递归算法的精髓是，调用自己．

关于KMP算法以及Boyer Moore算法的细节．

KMP算法在某个字符匹配失败的情况下，如果j>0.说明不是第一个了，那么这个时候就可以用F[j-1],当前的j没有匹配上，然后就是j-1位匹配上了
．此时为了使得刚才的匹配还可以重用，就做这件事．如果j=0了，那么说明刚才的匹配不可能还可以重用了．此时，直接i = i+1，j已经是0了．

其实对于这两种字符串匹配算法，只要把握好KMP是在从前向后进行匹配而Boyer Moore是从后向前进行匹配．那么对于Boyer Moore要注意的地方
在于，加入匹配不上了，就要找到没有匹配上的这个字符在pattern中最后出现的位置，这里要注意，找到之后还是从最后开始比较的，这里i往前走
多少就有讲究了，如果last occurrence在当前位置的后面，那么就只要将pattern串往前移动１步，但是要注意这个时候i的位置是在每匹配到的j
的位置，所以说i = i + m - min(j, 1+l) where l = last[T[i]].

关于这两种算法的时间复杂度

对于KMP算法来说，注意到主串并不回溯，因而时间复杂度是O(m+n)，而对于Boyer Moore算法，在最环情况下，比如aaaaaaa....和baaa，
每三次成功匹配后，pattern串只往前走一步，时间复杂度为O(mn)

